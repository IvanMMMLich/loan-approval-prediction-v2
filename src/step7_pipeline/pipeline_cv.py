"""
Step 7-9: Pipeline + Cross-Validation + Feature Analysis

============================================================================
–ß–¢–û –î–ï–õ–ê–ï–ú:
============================================================================

1. –°–æ–∑–¥–∞—ë–º Pipeline –±–µ–∑ data leakage:
   - Box-Cox –¥–ª—è person_income
   - Ordinal Encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö
   - LightGBM —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

2. 5-Fold Cross-Validation:
   - –ù–∞–¥—ë–∂–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
   - –°—Ä–µ–¥–Ω–µ–µ ¬± std –¥–ª—è –≤—Å–µ—Ö –º–µ—Ç—Ä–∏–∫

3. Feature Importance:
   - –ê–Ω–∞–ª–∏–∑ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
   - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ—Ç–±–æ—Ä—É

============================================================================
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold, cross_validate
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import PowerTransformer, FunctionTransformer, OrdinalEncoder
from lightgbm import LGBMClassifier
from pathlib import Path
import sys
import warnings
warnings.filterwarnings('ignore')

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ utils
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT / 'src'))

from utils.metrics import calculate_all_metrics, print_metrics

# ============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ò –ü–£–¢–ï–ô
# ============================================================================

# –ë–µ—Ä—ë–º –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ step4 (–¥–æ –≤—Å–µ—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π!)
DATA_DIR = PROJECT_ROOT / 'data' / 'processed'
RESULTS_DIR = PROJECT_ROOT / 'results' / 'step7_final_pipeline'

TRAIN_FILE = DATA_DIR / 'train_step4_2.csv'
TEST_FILE = DATA_DIR / 'test_step4_2.csv'

RESULTS_DIR.mkdir(parents=True, exist_ok=True)
(RESULTS_DIR / 'tables').mkdir(parents=True, exist_ok=True)


# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ Optuna
BEST_PARAMS = {
    'n_estimators': 836,
    'max_depth': 12,
    'learning_rate': 0.033018,
    'num_leaves': 23,
    'min_child_samples': 40,
    'subsample': 0.647898,
    'colsample_bytree': 0.574083,
    'reg_alpha': 4.743694,
    'reg_lambda': 0.408280,
    'class_weight': 'balanced',
    'random_state': 42,
    'n_jobs': -1,
    'verbose': -1
}

# –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ —Ç–∏–ø–∞–º
NUMERIC_FEATURES = ['person_income', 'person_emp_length', 'loan_amnt', 
                    'loan_int_rate', 'loan_percent_income']

CATEGORICAL_FEATURES = ['person_home_ownership', 'loan_intent', 
                        'loan_grade', 'cb_person_default_on_file']

# Ordinal Encoding –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–≤ –ø–æ—Ä—è–¥–∫–µ!)
ORDINAL_CATEGORIES = [
    ['RENT', 'OTHER', 'MORTGAGE', 'OWN'],  # person_home_ownership
    ['DEBTCONSOLIDATION', 'MEDICAL', 'HOMEIMPROVEMENT', 
     'PERSONAL', 'EDUCATION', 'VENTURE'],  # loan_intent
    ['G', 'F', 'E', 'D', 'C', 'B', 'A'],  # loan_grade
    ['Y', 'N']  # cb_person_default_on_file
]

TARGET = 'loan_status'


# ============================================================================
# –°–û–ó–î–ê–ù–ò–ï PIPELINE
# ============================================================================

def create_pipeline():
    """
    –°–æ–∑–¥–∞—ë—Ç Pipeline —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–∞–Ω–Ω—ã—Ö.
    
    –ü–æ—Ä—è–¥–æ–∫:
    1. ColumnTransformer:
       - Box-Cox –¥–ª—è person_income
       - Passthrough –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö
       - OrdinalEncoder –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö
    2. LightGBM
    """
    
    # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    # Box-Cox —Ç–æ–ª—å–∫–æ –¥–ª—è income (–æ—Å—Ç–∞–ª—å–Ω—ã–µ passthrough)
    numeric_transformer = ColumnTransformer(
        transformers=[
            ('boxcox_income', PowerTransformer(method='box-cox', standardize=True), 
             ['person_income']),
            ('passthrough_numeric', 'passthrough', 
             ['person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income'])
        ],
        remainder='drop'
    )
    
    # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö
    categorical_transformer = OrdinalEncoder(
        categories=ORDINAL_CATEGORIES,
        handle_unknown='use_encoded_value',
        unknown_value=-1
    )
    
    # –û–±—â–∏–π –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, NUMERIC_FEATURES),
            ('cat', categorical_transformer, CATEGORICAL_FEATURES)
        ],
        remainder='drop'
    )
    
    # –ü–æ–ª–Ω—ã–π Pipeline
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', LGBMClassifier(**BEST_PARAMS))
    ])
    
    return pipeline


# ============================================================================
# CROSS-VALIDATION
# ============================================================================

def run_cross_validation(X, y, n_splits=5):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç 5-Fold Stratified Cross-Validation.
    
    Returns:
        dict: –°—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –∏ –∏—Ö std
    """
    
    pipeline = create_pipeline()
    
    # Stratified K-Fold
    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è CV
    scoring = {
        'roc_auc': 'roc_auc',
        'accuracy': 'accuracy',
        'precision': 'precision',
        'recall': 'recall',
        'f1': 'f1'
    }
    
    print(f"\n   –ó–∞–ø—É—Å–∫ {n_splits}-Fold Cross-Validation...")
    print(f"   –≠—Ç–æ –∑–∞–π–º—ë—Ç –ø–∞—Ä—É –º–∏–Ω—É—Ç...\n")
    
    # Cross-validation
    cv_results = cross_validate(
        pipeline, X, y,
        cv=cv,
        scoring=scoring,
        return_train_score=False,
        n_jobs=-1
    )
    
    # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results = {}
    for metric in scoring.keys():
        scores = cv_results[f'test_{metric}']
        results[metric] = {
            'mean': scores.mean(),
            'std': scores.std(),
            'scores': scores
        }
    
    return results


# ============================================================================
# FEATURE IMPORTANCE
# ============================================================================

def analyze_feature_importance(X, y):
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    """
    
    pipeline = create_pipeline()
    pipeline.fit(X, y)
    
    # –ü–æ–ª—É—á–∞–µ–º –≤–∞–∂–Ω–æ—Å—Ç—å –∏–∑ LightGBM
    importance = pipeline.named_steps['classifier'].feature_importances_
    
    # –ò–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    feature_names = (
        ['person_income_boxcox'] + 
        ['person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income'] +
        CATEGORICAL_FEATURES
    )
    
    # DataFrame —Å –≤–∞–∂–Ω–æ—Å—Ç—å—é
    importance_df = pd.DataFrame({
        '–ü—Ä–∏–∑–Ω–∞–∫': feature_names,
        'Importance': importance
    }).sort_values('Importance', ascending=False)
    
    importance_df['Importance_pct'] = (
        importance_df['Importance'] / importance_df['Importance'].sum() * 100
    )
    
    return importance_df, pipeline


# ============================================================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================================

def main():
    print("\n" + "="*70)
    print("STEP 7-9: PIPELINE + CROSS-VALIDATION + FEATURE ANALYSIS")
    print("="*70)
    
    # ========================================================================
    # 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
    # ========================================================================
    print("\n" + "-"*70)
    print("1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
    print("-"*70)
    
    train = pd.read_csv(TRAIN_FILE)
    print(f"\n–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {train.shape[0]:,} —Å—Ç—Ä–æ–∫, {train.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
    print(f"–î–∞–Ω–Ω—ã–µ –∏–∑: step4_2 (–û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ï, –¥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–π)")
    
    X = train.drop(columns=[TARGET])
    y = train[TARGET]
    
    print(f"\n–ü—Ä–∏–∑–Ω–∞–∫–∏ ({len(X.columns)}):")
    print(f"   –ß–∏—Å–ª–æ–≤—ã–µ: {NUMERIC_FEATURES}")
    print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ: {CATEGORICAL_FEATURES}")
    
    # ========================================================================
    # 2. PIPELINE STRUCTURE
    # ========================================================================
    print("\n" + "-"*70)
    print("2. –°–¢–†–£–ö–¢–£–†–ê PIPELINE")
    print("-"*70)
    
    print("""
    Pipeline:
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  1. PREPROCESSOR (ColumnTransformer)                    ‚îÇ
    ‚îÇ     ‚îú‚îÄ‚îÄ person_income ‚Üí Box-Cox + Standardize           ‚îÇ
    ‚îÇ     ‚îú‚îÄ‚îÄ person_emp_length, loan_amnt, ... ‚Üí Passthrough ‚îÇ
    ‚îÇ     ‚îî‚îÄ‚îÄ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ ‚Üí OrdinalEncoder                 ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ  2. CLASSIFIER (LightGBM —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏)         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    
    ‚úÖ –í—Å–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤–Ω—É—Ç—Ä–∏ Pipeline
    ‚úÖ fit() —Ç–æ–ª—å–∫–æ –Ω–∞ train
    ‚úÖ –ù–µ—Ç data leakage!
    """)
    
    # ========================================================================
    # 3. 5-FOLD CROSS-VALIDATION
    # ========================================================================
    print("\n" + "-"*70)
    print("3. 5-FOLD CROSS-VALIDATION")
    print("-"*70)
    
    cv_results = run_cross_validation(X, y, n_splits=5)
    
    print("\n   üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ CV:")
    print(f"   {'–ú–µ—Ç—Ä–∏–∫–∞':<15} {'Mean':>10} {'¬± Std':>10}")
    print(f"   {'-'*35}")
    
    for metric, values in cv_results.items():
        print(f"   {metric:<15} {values['mean']:>10.4f} ¬± {values['std']:>9.4f}")
    
    print(f"\n   –î–µ—Ç–∞–ª–∏ –ø–æ —Ñ–æ–ª–¥–∞–º (ROC-AUC):")
    for i, score in enumerate(cv_results['roc_auc']['scores'], 1):
        print(f"      Fold {i}: {score:.4f}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º CV —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    cv_df = pd.DataFrame({
        'Metric': list(cv_results.keys()),
        'Mean': [v['mean'] for v in cv_results.values()],
        'Std': [v['std'] for v in cv_results.values()]
    })
    cv_df.to_csv(RESULTS_DIR / 'tables' / 'cv_results.csv', index=False)
    
    # ========================================================================
    # 4. FEATURE IMPORTANCE
    # ========================================================================
    print("\n" + "-"*70)
    print("4. FEATURE IMPORTANCE")
    print("-"*70)
    
    importance_df, fitted_pipeline = analyze_feature_importance(X, y)
    
    print("\n   üìä –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í:")
    print(f"   {'–ü—Ä–∏–∑–Ω–∞–∫':<25} {'Importance':>12} {'%':>8}")
    print(f"   {'-'*45}")
    
    for _, row in importance_df.iterrows():
        bar = '‚ñà' * int(row['Importance_pct'] / 2)
        print(f"   {row['–ü—Ä–∏–∑–Ω–∞–∫']:<25} {row['Importance']:>12.4f} {row['Importance_pct']:>7.1f}% {bar}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º importance
    importance_df.to_csv(RESULTS_DIR / 'tables' / 'feature_importance.csv', index=False)
    
    # ========================================================================
    # 5. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
    # ========================================================================
    print("\n" + "-"*70)
    print("5. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –ü–†–ò–ó–ù–ê–ö–ê–ú")
    print("-"*70)
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å –Ω–∏–∑–∫–æ–π –≤–∞–∂–Ω–æ—Å—Ç—å—é (< 5%)
    low_importance = importance_df[importance_df['Importance_pct'] < 5]
    high_importance = importance_df[importance_df['Importance_pct'] >= 5]
    
    print(f"\n   ‚úÖ –í–ê–ñ–ù–´–ï –ø—Ä–∏–∑–Ω–∞–∫–∏ (>= 5%):")
    for _, row in high_importance.iterrows():
        print(f"      ‚Ä¢ {row['–ü—Ä–∏–∑–Ω–∞–∫']}: {row['Importance_pct']:.1f}%")
    
    print(f"\n   ‚ö†Ô∏è  –°–õ–ê–ë–´–ï –ø—Ä–∏–∑–Ω–∞–∫–∏ (< 5%):")
    for _, row in low_importance.iterrows():
        print(f"      ‚Ä¢ {row['–ü—Ä–∏–∑–Ω–∞–∫']}: {row['Importance_pct']:.1f}%")
    
    print(f"""
   üí° –†–ï–®–ï–ù–ò–ï:
      –û—Å—Ç–∞–≤–ª—è–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ‚Äî LightGBM —Å–∞–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç –≤–µ—Å–∞.
      –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª–∞–±—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ä–µ–¥–∫–æ —É–ª—É—á—à–∞–µ—Ç –±—É—Å—Ç–∏–Ω–≥.
    """)
    
    # ========================================================================
    # –ò–¢–û–ì–ò
    # ========================================================================
    print("\n" + "="*70)
    print("–ò–¢–û–ì–ò")
    print("="*70)
    
    print(f"""
    ‚úÖ Pipeline —Å–æ–∑–¥–∞–Ω –ë–ï–ó data leakage
    ‚úÖ 5-Fold CV: ROC-AUC = {cv_results['roc_auc']['mean']:.4f} ¬± {cv_results['roc_auc']['std']:.4f}
    ‚úÖ Feature Importance –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω
    
    üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {RESULTS_DIR}
       ‚Ä¢ cv_results.csv
       ‚Ä¢ feature_importance.csv
    
    ‚û°Ô∏è  –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: python final_submission.py
    """)
    
    return fitted_pipeline, cv_results, importance_df


if __name__ == '__main__':
    main()