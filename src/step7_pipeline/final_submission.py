"""
Step 10: Final Training + Submission

============================================================================
–ß–¢–û –î–ï–õ–ê–ï–ú:
============================================================================

1. –û–±—É—á–∞–µ–º Pipeline –Ω–∞ –í–°–ï–• train –¥–∞–Ω–Ω—ã—Ö
2. –ú–µ—Ç—Ä–∏–∫–∏ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞ Train (ROC-AUC ~0.97)
3. Feature Importance –∞–Ω–∞–ª–∏–∑
4. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ test
5. –°–æ–∑–¥–∞—ë–º submission.csv –¥–ª—è Kaggle

============================================================================
"""

import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import PowerTransformer, OrdinalEncoder
from lightgbm import LGBMClassifier
from pathlib import Path
import pickle
import sys
import warnings
warnings.filterwarnings('ignore')

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ utils
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT / 'src'))

from utils.metrics import calculate_all_metrics, print_metrics, save_metrics
from utils.plotting import plot_all_model_visualizations
from utils.analysis import run_full_analysis

# ============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ò –ü–£–¢–ï–ô
# ============================================================================

DATA_DIR = PROJECT_ROOT / 'data' / 'processed'
RESULTS_DIR = PROJECT_ROOT / 'results' / 'step7_final_pipeline'
SUBMISSION_DIR = PROJECT_ROOT / 'data' / 'submissions'

TRAIN_FILE = DATA_DIR / 'train_step4_2.csv'
TEST_FILE = DATA_DIR / 'test_step4_2.csv'

RESULTS_DIR.mkdir(parents=True, exist_ok=True)
SUBMISSION_DIR.mkdir(parents=True, exist_ok=True)
(RESULTS_DIR / 'figures').mkdir(parents=True, exist_ok=True)
(RESULTS_DIR / 'tables').mkdir(parents=True, exist_ok=True)


# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

# –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ Optuna
BEST_PARAMS = {
    'n_estimators': 836,
    'max_depth': 12,
    'learning_rate': 0.033018,
    'num_leaves': 23,
    'min_child_samples': 40,
    'subsample': 0.647898,
    'colsample_bytree': 0.574083,
    'reg_alpha': 4.743694,
    'reg_lambda': 0.408280,
    'class_weight': 'balanced',
    'random_state': 42,
    'n_jobs': -1,
    'verbose': -1
}

# –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ —Ç–∏–ø–∞–º
NUMERIC_FEATURES = ['person_income', 'person_emp_length', 'loan_amnt', 
                    'loan_int_rate', 'loan_percent_income']

CATEGORICAL_FEATURES = ['person_home_ownership', 'loan_intent', 
                        'loan_grade', 'cb_person_default_on_file']

# Ordinal Encoding –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
ORDINAL_CATEGORIES = [
    ['RENT', 'OTHER', 'MORTGAGE', 'OWN'],
    ['DEBTCONSOLIDATION', 'MEDICAL', 'HOMEIMPROVEMENT', 
     'PERSONAL', 'EDUCATION', 'VENTURE'],
    ['G', 'F', 'E', 'D', 'C', 'B', 'A'],
    ['Y', 'N']
]

TARGET = 'loan_status'


# ============================================================================
# –°–û–ó–î–ê–ù–ò–ï PIPELINE
# ============================================================================

def create_pipeline():
    """–°–æ–∑–¥–∞—ë—Ç Pipeline."""
    
    numeric_transformer = ColumnTransformer(
        transformers=[
            ('boxcox_income', PowerTransformer(method='box-cox', standardize=True), 
             ['person_income']),
            ('passthrough_numeric', 'passthrough', 
             ['person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income'])
        ],
        remainder='drop'
    )
    
    categorical_transformer = OrdinalEncoder(
        categories=ORDINAL_CATEGORIES,
        handle_unknown='use_encoded_value',
        unknown_value=-1
    )
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, NUMERIC_FEATURES),
            ('cat', categorical_transformer, CATEGORICAL_FEATURES)
        ],
        remainder='drop'
    )
    
    pipeline = Pipeline([
        ('preprocessor', preprocessor),
        ('classifier', LGBMClassifier(**BEST_PARAMS))
    ])
    
    return pipeline


# ============================================================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================================

def main():
    print("\n" + "="*70)
    print("STEP 10: FINAL TRAINING + SUBMISSION")
    print("="*70)
    
    # ========================================================================
    # 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
    # ========================================================================
    print("\n" + "-"*70)
    print("1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
    print("-"*70)
    
    train = pd.read_csv(TRAIN_FILE)
    test = pd.read_csv(TEST_FILE)
    
    print(f"\nTrain: {train.shape[0]:,} —Å—Ç—Ä–æ–∫, {train.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
    print(f"Test:  {test.shape[0]:,} —Å—Ç—Ä–æ–∫, {test.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
    
    X_full = train.drop(columns=[TARGET])
    y_full = train[TARGET]
    X_test = test.copy()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ id –≤ test
    if 'id' in X_test.columns:
        test_ids = X_test['id'].copy()
        X_test = X_test.drop(columns=['id'])
    else:
        test_ids = pd.Series(range(len(X_test)), name='id')
    
    print(f"\n–ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {list(X_full.columns)}")
    
    # ========================================================================
    # 2. –û–ë–£–ß–ï–ù–ò–ï –ù–ê –í–°–ï–• –î–ê–ù–ù–´–•
    # ========================================================================
    print("\n" + "-"*70)
    print("2. –û–ë–£–ß–ï–ù–ò–ï –ù–ê –í–°–ï–• –î–ê–ù–ù–´–•")
    print("-"*70)
    
    pipeline = create_pipeline()
    
    print("\n   –û–±—É—á–µ–Ω–∏–µ Pipeline –Ω–∞ –í–°–ï–• train –¥–∞–Ω–Ω—ã—Ö...")
    pipeline.fit(X_full, y_full)
    print("   ‚úì –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    
    # ========================================================================
    # 3. –ú–ï–¢–†–ò–ö–ò –ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø (–Ω–∞ Train)
    # ========================================================================
    print("\n" + "-"*70)
    print("3. –ú–ï–¢–†–ò–ö–ò –ò –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø (Train)")
    print("-"*70)
    
    y_pred = pipeline.predict(X_full)
    y_pred_proba = pipeline.predict_proba(X_full)[:, 1]
    
    metrics = calculate_all_metrics(y_full, y_pred, y_pred_proba)
    print_metrics(metrics, title="LightGBM Final (Train)")
    save_metrics(metrics, RESULTS_DIR / 'tables' / 'final_metrics.csv')
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
    plot_all_model_visualizations(
        y_true=y_full,
        y_pred=y_pred,
        y_pred_proba=y_pred_proba,
        metrics_dict=metrics,
        model_name="LightGBM_Final",
        save_dir=RESULTS_DIR / 'figures'
    )
    
    # ========================================================================
    # 4. FEATURE IMPORTANCE ANALYSIS
    # ========================================================================
    print("\n" + "-"*70)
    print("4. FEATURE IMPORTANCE ANALYSIS")
    print("-"*70)
    
    # –ü–æ–ª—É—á–∞–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    X_transformed = pipeline.named_steps['preprocessor'].transform(X_full)
    
    # –ò–º–µ–Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ—Å–ª–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    feature_names = (
        ['person_income_boxcox'] + 
        ['person_emp_length', 'loan_amnt', 'loan_int_rate', 'loan_percent_income'] +
        CATEGORICAL_FEATURES
    )
    
    X_df = pd.DataFrame(X_transformed, columns=feature_names)
    
    # –ê–Ω–∞–ª–∏–∑ —Å Permutation Importance
    run_full_analysis(
        X_train=X_df,
        y_train=y_full.reset_index(drop=True),
        X_val=X_df,
        y_val=y_full.reset_index(drop=True),
        model=pipeline.named_steps['classifier'],
        new_features=['person_income_boxcox'],
        save_dir=RESULTS_DIR,
        top_n=9
    )
    
    # ========================================================================
    # 5. –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –ù–ê TEST
    # ========================================================================
    print("\n" + "-"*70)
    print("5. –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø –ù–ê TEST")
    print("-"*70)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    test_pred = pipeline.predict(X_test)
    test_proba = pipeline.predict_proba(X_test)[:, 1]
    
    print(f"\n   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–¥–µ–ª–∞–Ω—ã!")
    print(f"\n   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
    print(f"      –ö–ª–∞—Å—Å 0 (–æ—Ç–∫–∞–∑):    {(test_pred == 0).sum():,} ({(test_pred == 0).mean()*100:.1f}%)")
    print(f"      –ö–ª–∞—Å—Å 1 (–æ–¥–æ–±—Ä–µ–Ω):  {(test_pred == 1).sum():,} ({(test_pred == 1).mean()*100:.1f}%)")
    
    print(f"\n   –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:")
    print(f"      Min:    {test_proba.min():.4f}")
    print(f"      Max:    {test_proba.max():.4f}")
    print(f"      Mean:   {test_proba.mean():.4f}")
    print(f"      Median: {np.median(test_proba):.4f}")
    
    # ========================================================================
    # 6. –°–û–ó–î–ê–ù–ò–ï SUBMISSION
    # ========================================================================
    print("\n" + "-"*70)
    print("6. –°–û–ó–î–ê–ù–ò–ï SUBMISSION")
    print("-"*70)
    
    # Submission —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ (–æ–±—ã—á–Ω–æ –ª—É—á—à–µ –¥–ª—è Kaggle)
    submission_proba = pd.DataFrame({
        'id': test_ids,
        'loan_status': test_proba
    })
    
    # Submission —Å –∫–ª–∞—Å—Å–∞–º–∏
    submission_class = pd.DataFrame({
        'id': test_ids,
        'loan_status': test_pred
    })
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    submission_proba_path = SUBMISSION_DIR / 'submission_proba.csv'
    submission_class_path = SUBMISSION_DIR / 'submission_class.csv'
    
    submission_proba.to_csv(submission_proba_path, index=False)
    submission_class.to_csv(submission_class_path, index=False)
    
    print(f"\n   ‚úì Submission —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã:")
    print(f"      ‚Ä¢ {submission_proba_path} (–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)")
    print(f"      ‚Ä¢ {submission_class_path} (–∫–ª–∞—Å—Å—ã)")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
    print(f"\n   –ü—Ä–µ–≤—å—é submission_proba.csv:")
    print(submission_proba.head(10).to_string(index=False))
    
    # ========================================================================
    # 7. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò
    # ========================================================================
    print("\n" + "-"*70)
    print("7. –°–û–•–†–ê–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ò")
    print("-"*70)
    
    model_path = RESULTS_DIR / 'final_pipeline.pkl'
    with open(model_path, 'wb') as f:
        pickle.dump(pipeline, f)
    
    print(f"\n   ‚úì Pipeline —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {model_path}")
    
    # ========================================================================
    # –ò–¢–û–ì–ò
    # ========================================================================
    print("\n" + "="*70)
    print("–ì–û–¢–û–í–û! üéâ")
    print("="*70)
    
    print(f"""
    ‚úÖ Pipeline –æ–±—É—á–µ–Ω –Ω–∞ {len(X_full):,} –ø—Ä–∏–º–µ—Ä–∞—Ö
    ‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–¥–µ–ª–∞–Ω—ã –¥–ª—è {len(X_test):,} –ø—Ä–∏–º–µ—Ä–æ–≤
    ‚úÖ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞
    ‚úÖ Submission —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã
    
    üìä Train –º–µ—Ç—Ä–∏–∫–∏:
       ROC-AUC:  {metrics['ROC-AUC']:.4f}
       Accuracy: {metrics['Accuracy']:.4f}
       Recall:   {metrics['Recall']:.4f}
       F1-Score: {metrics['F1-Score']:.4f}
    
    üìÅ –§–∞–π–ª—ã:
       ‚Ä¢ {RESULTS_DIR / 'figures'} (–≥—Ä–∞—Ñ–∏–∫–∏)
       ‚Ä¢ {RESULTS_DIR / 'tables'} (—Ç–∞–±–ª–∏—Ü—ã)
       ‚Ä¢ {submission_proba_path}
       ‚Ä¢ {submission_class_path}
       ‚Ä¢ {model_path}
    
    üì§ –î–ª—è Kaggle:
       –ó–∞–≥—Ä—É–∑–∏—Ç–µ submission_proba.csv (–µ—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∞ ROC-AUC)
       –∏–ª–∏ submission_class.csv (–µ—Å–ª–∏ –º–µ—Ç—Ä–∏–∫–∞ Accuracy/F1)
    
    üèÜ –û–∂–∏–¥–∞–µ–º—ã–π ROC-AUC –Ω–∞ Kaggle: ~0.955-0.960
    """)


if __name__ == '__main__':
    main()