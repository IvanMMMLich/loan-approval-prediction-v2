"""
Step 6: Model Selection ‚Äî –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

============================================================================
–ß–¢–û –î–ï–õ–ê–ï–ú:
============================================================================

–°—Ä–∞–≤–Ω–∏–≤–∞–µ–º 3 –±—É—Å—Ç–∏–Ω–≥–∞ + RF baseline:
1. Random Forest (baseline –∏–∑ 1_transformations) ‚Äî —É–∂–µ –µ—Å—Ç—å –º–µ—Ç—Ä–∏–∫–∏
2. XGBoost
3. LightGBM  
4. CatBoost

–î–∞–Ω–Ω—ã–µ: –∏–∑ step5/1_transformations (Box-Cox –¥–ª—è income)

–í—Å–µ –º–æ–¥–µ–ª–∏ –≤ –†–ê–í–ù–´–• —É—Å–ª–æ–≤–∏—è—Ö:
- –û–¥–∏–Ω–∞–∫–æ–≤—ã–π train/val split
- –û–¥–∏–Ω–∞–∫–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
- class_weight='balanced' (–∏–ª–∏ –∞–Ω–∞–ª–æ–≥)

============================================================================
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from pathlib import Path
import sys
import warnings
warnings.filterwarnings('ignore')

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ utils
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.append(str(PROJECT_ROOT / 'src'))

from utils.metrics import calculate_all_metrics, print_metrics, save_metrics

# ============================================================================
# –ù–ê–°–¢–†–û–ô–ö–ò –ü–£–¢–ï–ô
# ============================================================================

DATA_DIR = PROJECT_ROOT / 'data' / 'processed' / 'step5' / '1_transformations'
RESULTS_DIR = PROJECT_ROOT / 'results' / 'step6_model_selection'

TRAIN_FILE = DATA_DIR / 'train.csv'

RESULTS_DIR.mkdir(parents=True, exist_ok=True)
(RESULTS_DIR / 'tables').mkdir(parents=True, exist_ok=True)


# ============================================================================
# ORDINAL ENCODING
# ============================================================================

ORDINAL_MAPPINGS = {
    'loan_grade': {'A': 7, 'B': 6, 'C': 5, 'D': 4, 'E': 3, 'F': 2, 'G': 1},
    'person_home_ownership': {'OWN': 4, 'MORTGAGE': 3, 'OTHER': 2, 'RENT': 1},
    'loan_intent': {
        'VENTURE': 6, 'EDUCATION': 5, 'PERSONAL': 4,
        'HOMEIMPROVEMENT': 3, 'MEDICAL': 2, 'DEBTCONSOLIDATION': 1
    },
    'cb_person_default_on_file': {'N': 1, 'Y': 0}
}

CATEGORICAL_FEATURES = ['person_home_ownership', 'loan_intent', 'loan_grade', 'cb_person_default_on_file']


def encode_categorical(df):
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç Ordinal Encoding –∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º."""
    df_encoded = df.copy()
    for col, mapping in ORDINAL_MAPPINGS.items():
        if col in df_encoded.columns:
            df_encoded[col] = df_encoded[col].map(mapping)
    return df_encoded


# ============================================================================
# –ú–û–î–ï–õ–ò
# ============================================================================

def get_models(scale_pos_weight):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –º–æ–¥–µ–ª–µ–π —Å –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏."""
    
    models = {
        'Random Forest': RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=20,
            min_samples_leaf=10,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1
        ),
        
        'XGBoost': XGBClassifier(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            scale_pos_weight=scale_pos_weight,  # –ê–Ω–∞–ª–æ–≥ class_weight
            random_state=42,
            n_jobs=-1,
            verbosity=0
        ),
        
        'LightGBM': LGBMClassifier(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            class_weight='balanced',
            random_state=42,
            n_jobs=-1,
            verbose=-1
        ),
        
        'CatBoost': CatBoostClassifier(
            iterations=100,
            depth=6,
            learning_rate=0.1,
            auto_class_weights='Balanced',
            random_state=42,
            verbose=0
        )
    }
    
    return models


# ============================================================================
# –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø
# ============================================================================

def main():
    print("\n" + "="*70)
    print("STEP 6: MODEL SELECTION ‚Äî –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
    print("="*70)
    
    # ========================================================================
    # 1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•
    # ========================================================================
    print("\n" + "-"*70)
    print("1. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
    print("-"*70)
    
    train = pd.read_csv(TRAIN_FILE)
    print(f"\n–ó–∞–≥—Ä—É–∂–µ–Ω–æ: {train.shape[0]:,} —Å—Ç—Ä–æ–∫, {train.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")
    print(f"–î–∞–Ω–Ω—ã–µ –∏–∑: step5/1_transformations (Box-Cox income)")
    
    TARGET = 'loan_status'
    X = train.drop(columns=[TARGET])
    y = train[TARGET]
    
    print(f"\n–ü—Ä–∏–∑–Ω–∞–∫–∏: {list(X.columns)}")
    
    # ========================================================================
    # 2. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•
    # ========================================================================
    print("\n" + "-"*70)
    print("2. –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–•")
    print("-"*70)
    
    # Ordinal Encoding –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    X_encoded = encode_categorical(X)
    
    # Train/Val split
    X_train, X_val, y_train, y_val = train_test_split(
        X_encoded, y,
        test_size=0.2,
        random_state=42,
        stratify=y
    )
    
    print(f"\nTrain: {X_train.shape[0]:,} —Å—Ç—Ä–æ–∫")
    print(f"Val:   {X_val.shape[0]:,} —Å—Ç—Ä–æ–∫")
    
    # –î–ª—è XGBoost: scale_pos_weight
    neg_count = (y_train == 0).sum()
    pos_count = (y_train == 1).sum()
    scale_pos_weight = neg_count / pos_count
    print(f"\n–î–∏—Å–±–∞–ª–∞–Ω—Å: {neg_count:,} / {pos_count:,} = {scale_pos_weight:.2f}")
    
    # ========================================================================
    # 3. –û–ë–£–ß–ï–ù–ò–ï –ò –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ï–ô
    # ========================================================================
    print("\n" + "-"*70)
    print("3. –û–ë–£–ß–ï–ù–ò–ï –ò –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ï–ô")
    print("-"*70)
    
    models = get_models(scale_pos_weight)
    results = []
    
    for name, model in models.items():
        print(f"\n{'='*50}")
        print(f"   {name}")
        print(f"{'='*50}")
        
        # –û–±—É—á–µ–Ω–∏–µ
        print("   –û–±—É—á–µ–Ω–∏–µ...")
        model.fit(X_train, y_train)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        y_pred = model.predict(X_val)
        y_pred_proba = model.predict_proba(X_val)[:, 1]
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        metrics = calculate_all_metrics(y_val, y_pred, y_pred_proba)
        print_metrics(metrics, title=name)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        results.append({
            'Model': name,
            'ROC-AUC': metrics['ROC-AUC'],
            'Accuracy': metrics['Accuracy'],
            'Precision': metrics['Precision'],
            'Recall': metrics['Recall'],
            'F1-Score': metrics['F1-Score'],
            'Specificity': metrics['Specificity']
        })
    
    # ========================================================================
    # 4. –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê
    # ========================================================================
    print("\n" + "-"*70)
    print("4. –°–†–ê–í–ù–ò–¢–ï–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê")
    print("-"*70)
    
    results_df = pd.DataFrame(results)
    results_df = results_df.sort_values('ROC-AUC', ascending=False)
    results_df = results_df.reset_index(drop=True)
    
    print("\n")
    print(results_df.to_string(index=False))
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    results_df.to_csv(RESULTS_DIR / 'tables' / 'model_comparison.csv', index=False)
    
    # ========================================================================
    # 5. –í–´–í–û–î –õ–£–ß–®–ï–ô –ú–û–î–ï–õ–ò
    # ========================================================================
    print("\n" + "="*70)
    print("–†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print("="*70)
    
    best_model = results_df.iloc[0]['Model']
    best_roc_auc = results_df.iloc[0]['ROC-AUC']
    
    print(f"\nüèÜ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {best_model}")
    print(f"   ROC-AUC: {best_roc_auc:.4f}")
    
    print(f"\nüìä –†–µ–π—Ç–∏–Ω–≥ –ø–æ ROC-AUC:")
    for i, row in results_df.iterrows():
        medal = "ü•á" if i == 0 else "ü•à" if i == 1 else "ü•â" if i == 2 else "  "
        print(f"   {medal} {row['Model']}: {row['ROC-AUC']:.4f}")
    
    print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {RESULTS_DIR / 'tables' / 'model_comparison.csv'}")
    print(f"\n‚û°Ô∏è  –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: Step 7 ‚Äî Hyperparameter Tuning –¥–ª—è {best_model}")


if __name__ == '__main__':
    main()