# Loan Approval Prediction

Прогнозирование одобрения кредита — проект по машинному обучению для предсказания вероятности одобрения кредитной заявки.

**Автор:** Сычёв Иван Александрович  
**Год:** 2025  
**Тип задачи:** Бинарная классификация  
**Целевая метрика:** ROC-AUC  

---

## Содержание

- [Цели и задачи](#цели-и-задачи)
- [Ключевое открытие: Subprime Lending](#ключевое-открытие-subprime-lending)
- [Принципы разработки](#принципы-разработки)
- [Утилиты проекта](#утилиты-проекта)
- [Структура проекта](#структура-проекта)
- [Описание этапов работы](#описание-этапов-работы)
- [Результаты](#результаты)
- [Как запустить](#как-запустить)
- [Выводы](#выводы)

---

## Цели и задачи

Целью проекта является построение модели машинного обучения для предсказания одобрения кредита. Целевая переменная `loan_status` принимает значения 0 (отказ) и 1 (одобрение).

В ходе работы решались следующие задачи: проведение разведочного анализа данных с раздельным изучением числовых и категориальных признаков, анализ зависимостей множеством методов, очистка и подготовка данных, создание новых признаков с проверкой их полезности, сравнение нескольких моделей машинного обучения, оптимизация гиперпараметров лучшей модели, построение Pipeline без утечки данных и формирование submission для Kaggle.

---

## Ключевое открытие: Subprime Lending

В процессе анализа зависимостей на третьем этапе было сделано важное открытие, которое изменило понимание данных и повлияло на все дальнейшие решения.

Изначально ожидалось, что данные следуют классической банковской логике: клиенты с высоким доходом, хорошей кредитной историей и низким грейдом риска должны чаще получать одобрение. Однако корреляционный анализ показал обратную картину.

Выяснилось, что датасет представляет **subprime кредитора** — финансовую организацию, специализирующуюся на выдаче кредитов клиентам с повышенным риском. В такой модели бизнеса высокорисковые клиенты являются целевой аудиторией, поскольку они приносят больший доход за счёт повышенных процентных ставок.

Это открытие объясняет, почему клиенты с грейдами D, E, F, G имеют более высокий approval rate, почему клиенты с историей дефолта чаще получают одобрение (Y = 30% одобрений vs N = 12%), и почему высокая процентная ставка коррелирует с одобрением (средняя ставка одобренных 13.20% vs отклонённых 10.26%).

Понимание природы данных позволило правильно настроить Ordinal Encoding — порядок категорий был выстроен с учётом логики subprime кредитора, а не классического банка.

---

## Принципы разработки

### Чистый код и модульность

С самого начала проект строился по принципу разделения ответственности. Весь повторяющийся код был вынесен в отдельные утилиты в папке `src/utils/`. Это позволило на каждом этапе работы вызывать одни и те же функции анализа, получая сопоставимые результаты и экономя время на написании повторяющегося кода.

### Baseline подход

На каждом этапе работы запускалась baseline модель для оценки текущего состояния данных. Это позволяло объективно отслеживать влияние каждого изменения на качество предсказаний. Начиная с простой логистической регрессии на первом этапе, мы постепенно улучшали результаты, и каждое улучшение было подтверждено метриками.

### Строгая валидация

Во всех экспериментах использовался Train/Val Split в соотношении 80/20 с сохранением баланса классов через параметр stratify. Для финальной оценки модели применялась 5-Fold Cross-Validation. Все эксперименты воспроизводимы благодаря фиксированному random_state=42.

---

## Утилиты проекта

Все переиспользуемые функции вынесены в папку `src/utils/`.

### metrics.py — Метрики классификации

Файл содержит функции для расчёта и визуализации всех основных метрик бинарной классификации:

- **Матрица ошибок (Confusion Matrix)** — таблица 2×2, показывающая количество True Positive, False Positive, True Negative, False Negative предсказаний
- **ROC-кривая (Receiver Operating Characteristic)** — график зависимости True Positive Rate от False Positive Rate при различных порогах классификации
- **Accuracy (Точность)** — доля правильных предсказаний от общего числа
- **Precision (Точность положительного класса)** — доля истинно положительных среди всех предсказанных положительных
- **Recall (Полнота)** — доля найденных положительных от всех реально положительных
- **F1-Score** — гармоническое среднее Precision и Recall
- **Specificity (Специфичность)** — доля правильно определённых отрицательных классов

### plotting.py — Визуализация

Функции для построения графиков: ROC-кривая с AUC, матрица ошибок в виде heatmap, сравнение метрик моделей, графики распределений.

### analysis.py — Корреляционный анализ

Функции для расчёта корреляций различными методами, Permutation Importance, проверки мультиколлинеарности.

---

## Структура проекта

```
loan-approval-prediction-v2/
│
├── data/
│   ├── raw/                    # Исходные данные Kaggle
│   ├── processed/              # Обработанные данные по этапам
│   └── submissions/            # Файлы для отправки на Kaggle
│
├── src/
│   ├── step1_data_loading/     # Знакомство с данными
│   ├── step2_eda/              # Углубленный EDA
│   ├── step3_correlations/     # Анализ зависимостей (19 методов)
│   ├── step4_data_cleaning/    # Очистка данных
│   ├── step5_feature_engineering/  # Создание признаков
│   ├── step6_model_selection/  # Сравнение моделей и Optuna
│   ├── step7_final_pipeline/   # Финальный Pipeline и submission
│   └── utils/                  # Переиспользуемые утилиты
│       ├── metrics.py          # Метрики классификации
│       ├── plotting.py         # Визуализация
│       └── analysis.py         # Корреляционный анализ
│
└── results/                    # Графики, таблицы, сохранённые модели
```

---

## Описание этапов работы

### Step 1: Знакомство с данными

На первом этапе проводилось общее знакомство с данными. Тренировочный набор содержит 58 645 записей, тестовый — 39 098. Было проверено наличие пропусков и дубликатов — данные оказались чистыми. Построены общие распределения признаков, изучена структура категориальных переменных.

Уже на этом этапе была обучена первая baseline модель — логистическая регрессия. Это дало отправную точку для сравнения: ROC-AUC составил около 0.87.

**Что узнали:** Данные качественные, пропусков нет. Дисбаланс классов умеренный (около 78% отказов, 22% одобрений). Есть категориальные признаки, которые потребуют кодирования.

**Как используем дальше:** Понимание структуры данных позволяет спланировать углубленный анализ на следующем этапе.

Файлы: `src/step1_data_loading/`

### Step 2: Углубленный EDA

На втором этапе проводился детальный разведочный анализ отдельно для числовых и категориальных признаков.

**Числовые признаки.** Для каждого признака строились: гистограммы распределений, boxplot для выявления выбросов, расчёт асимметрии (skewness) и эксцесса (kurtosis), сравнение распределений по классам (одобрено/отклонено). Было обнаружено, что `person_income` имеет экстремальную асимметрию (skewness = 10.46), что указывало на необходимость трансформации. Признак `loan_int_rate` имеет симметричное нормальное распределение (skewness = 0.2). Выбросы выявлялись методом IQR — например, для `loan_int_rate` найдено 34 выброса (0.06%).

**Категориальные признаки.** Для каждой категории строились stacked bar chart с распределением по классам. Например, для `cb_person_default_on_file` видно, что клиенты с историей дефолта (Y) имеют значительно более высокий approval rate (~30%) по сравнению с клиентами без дефолта (N, ~12%).

**Что узнали:** Признак `person_income` требует трансформации из-за сильной асимметрии. Есть выбросы в возрасте и стаже работы. Категориальные признаки показывают разный approval rate по категориям — это будет полезно для понимания логики данных.

**Как используем дальше:** Информация об асимметрии `person_income` будет использована на этапе Feature Engineering для применения Box-Cox трансформации. Выбросы будут обработаны на этапе очистки.

Файлы: `src/step2_eda/`

### Step 3: Анализ зависимостей (19 методов)

Третий этап стал ключевым для понимания данных. Был проведён масштабный корреляционный анализ с использованием 19 различных методов, разделённых на 4 категории.

**Корреляции с таргетом (9 методов):**

| Метод | Название | Описание |
|-------|----------|----------|
| method1_pearson | Корреляция Пирсона | Линейная связь числовых признаков с таргетом |
| method2_point_biserial | Точечно-бисериальная корреляция | Связь числового признака с бинарным таргетом |
| method3_chi_square | Хи-квадрат тест | Статистическая значимость связи категорий с таргетом |
| method4_mutual_information | Взаимная информация | Нелинейная зависимость любых признаков |
| method5_anova_f | Дисперсионный анализ (ANOVA) | Различие средних по группам таргета |
| method6_rf_importance | Важность Random Forest | Встроенная важность признаков в дереве |
| method7_permutation_importance | Важность при перестановке | Падение метрики при случайном перемешивании |
| method8_logreg_coefficients | Коэффициенты логистической регрессии | Веса признаков в линейной модели |
| method9_rfe | Рекурсивное исключение признаков | Ранжирование по порядку исключения |

**Числовые корреляции между признаками (3 метода):**

| Метод | Название | Описание |
|-------|----------|----------|
| method10_pearson | Корреляция Пирсона | Линейная связь между числовыми признаками |
| method11_spearman | Корреляция Спирмена | Монотонная связь (устойчива к выбросам) |
| method12_distance_corr | Дистанционная корреляция | Нелинейная зависимость любого типа |

**Категориальные корреляции (2 метода):**

| Метод | Название | Описание |
|-------|----------|----------|
| method13_cramers_v | V Крамера | Сила связи между категориальными признаками |
| method14_uncertainty_coef | Коэффициент неопределённости | Асимметричная мера связи категорий |

**Смешанные корреляции (2 метода):**

| Метод | Название | Описание |
|-------|----------|----------|
| method15_eta_squared | Эта-квадрат | Доля дисперсии числового признака, объяснённая категорией |
| method16_kruskal_wallis | Критерий Краскела-Уоллиса | Непараметрический тест различий между группами |

**Model-based методы (3 метода):**

| Метод | Название | Описание |
|-------|----------|----------|
| method17_rf_pairwise | Попарная важность Random Forest | Важность пар признаков |
| method18_h_statistic | H-статистика взаимодействий | Сила взаимодействия между признаками |
| method19_permutation_conditional | Условная важность при перестановке | Важность с учётом других признаков |

Именно на этом этапе было сделано открытие о природе subprime кредитора. Корреляции показали, что высокий грейд риска и наличие дефолта положительно связаны с одобрением — логика, обратная классическому банку.

После понимания логики данных было решено сравнить два метода кодирования категориальных признаков. Обучены две модели Random Forest: с One-Hot Encoding и с Ordinal Encoding. Ordinal Encoding показал лучшие результаты, так как все категориальные признаки имеют естественный порядок, а древесные модели хорошо работают с порядковыми числами.

**Применённые маппинги Ordinal Encoding:**
- `loan_grade`: A=7, B=6, C=5, D=4, E=3, F=2, G=1
- `person_home_ownership`: OWN=4, MORTGAGE=3, OTHER=2, RENT=1
- `loan_intent`: VENTURE=6, EDUCATION=5, PERSONAL=4, HOMEIMPROVEMENT=3, MEDICAL=2, DEBTCONSOLIDATION=1
- `cb_person_default_on_file`: N=1, Y=0

**Baseline после Ordinal Encoding:** ROC-AUC улучшился до ~0.93

**Что узнали:** Данные представляют subprime кредитора с инвертированной логикой. Ordinal Encoding лучше One-Hot для наших данных. Признаки `person_age` и `person_emp_length` сильно коррелируют между собой.

**Как используем дальше:** Ordinal Encoding становится стандартом для всех последующих этапов. Знание о мультиколлинеарности age и emp_length поможет принять решение об удалении одного из них.

Файлы: `src/step3_correlations/`

### Step 4: Очистка данных

На основе EDA и корреляционного анализа были приняты решения по очистке данных.

Удалены записи с нереалистичными значениями: возраст более 100 лет, стаж работы более 60 лет. Для оставшихся выбросов применён capping — ограничение экстремальных значений границами разумного диапазона.

Признак `person_age` был удалён из-за высокой корреляции с `person_emp_length` (мультиколлинеарность). Они несли дублирующую информацию, и `person_emp_length` оказался более информативным для модели.

Все категориальные признаки были закодированы через Ordinal Encoding с маппингами, оптимизированными для древесных моделей.

**Baseline после очистки:** ROC-AUC улучшился до ~0.935

**Что узнали:** Удаление мультиколлинеарности и выбросов улучшает качество модели. После очистки осталось 9 признаков.

**Как используем дальше:** Чистые данные готовы для Feature Engineering и финального моделирования.

Файлы: `src/step4_data_cleaning/`  
Результат: `data/processed/train_step4_2.csv`, `data/processed/test_step4_2.csv`

### Step 5: Feature Engineering

Этот этап занял значительную часть работы. Было протестировано пять методов создания новых признаков, и каждый проверялся по строгому протоколу: корреляции Пирсона и Спирмена с таргетом, мультиколлинеарность с существующими признаками, Permutation Importance в baseline модели.

**Трансформации.** Box-Cox трансформация для `person_income` снизила skewness с 10.46 до 0.0002. Baseline после применения показал улучшение. Признак принят.

**Комбинации.** Признак `rate_burden` (комбинация ставки и дохода) показал мультиколлинеарность 0.91 с `loan_percent_income`. Отклонён.

**Агрегации.** Признак `rate_deviation` (отклонение ставки от средней по грейду) показал Permutation Importance близкий к нулю. Отклонён.

**Бинарные флаги.** Флаг `intent_default_risk` не улучшил метрики. Отклонён.

**Доменные признаки.** Не применялись, так как предыдущие методы не показали улучшений.

Из пяти методов только один оказался успешным — Box-Cox трансформация дохода.

**Baseline после Feature Engineering:** ROC-AUC ~0.937

**Что узнали:** Не количество признаков определяет качество модели, а их релевантность. Строгий протокол проверки предотвращает добавление бесполезных признаков.

Файлы: `src/step5_feature_engineering/`  
Результаты: `results/step5_feature_engineering/`

### Step 6: Сравнение моделей и оптимизация

На этом этапе перешли от baseline Random Forest к сравнению современных алгоритмов.

**Сравнение моделей:**

| Модель | ROC-AUC | Accuracy | Recall |
|--------|---------|----------|--------|
| LightGBM | 0.9552 | 0.9265 | 0.8329 |
| XGBoost | 0.9547 | 0.9311 | 0.8305 |
| CatBoost | 0.9440 | 0.9130 | 0.8132 |
| Random Forest | 0.9371 | 0.9305 | 0.7671 |

LightGBM показал лучший ROC-AUC и был выбран для оптимизации гиперпараметров.

**Optuna оптимизация:** 100 trials с 5-Fold CV. Optuna автоматически подобрала оптимальные гиперпараметры:

| Параметр | Значение | Описание |
|----------|----------|----------|
| n_estimators | 836 | Количество деревьев в ансамбле |
| max_depth | 12 | Максимальная глубина каждого дерева |
| learning_rate | 0.033 | Скорость обучения (вклад каждого дерева) |
| num_leaves | 23 | Максимальное количество листьев в дереве |
| min_child_samples | 40 | Минимум записей в листе (защита от переобучения) |
| subsample | 0.648 | Доля данных для обучения каждого дерева |
| colsample_bytree | 0.574 | Доля признаков для каждого дерева |
| reg_alpha | 4.74 | L1 регуляризация (разреживание весов) |
| reg_lambda | 0.41 | L2 регуляризация (сглаживание весов) |

**После Optuna:** ROC-AUC улучшился с 0.9552 до 0.9602

Файлы: `src/step6_model_selection/`  
Результаты: `results/step6_model_selection/`

### Step 7: Финальный Pipeline и Submission

На заключительном этапе создан sklearn Pipeline без утечки данных. Все трансформации выполняются внутри Pipeline: Box-Cox для дохода, Ordinal Encoding для категорий.

**Метрики на тренировочных данных:**

Финальная модель LightGBM с оптимизированными гиперпараметрами показала отличные результаты на тренировочных данных. ROC-AUC достиг 0.9756, что говорит о высокой разделяющей способности модели. Recall составил 0.8878 — модель находит 88.78% всех одобренных заявок. Матрица ошибок: TP=7413, TN=47319, FP=2976, FN=937.

| Метрика | Значение |
|---------|----------|
| ROC-AUC | 0.9756 |
| Accuracy | 0.9333 |
| Precision | 0.7135 |
| Recall | 0.8878 |
| F1-Score | 0.7912 |
| Specificity | 0.9408 |

**Метрики на тестовых данных (5-Fold Cross-Validation):**

Для честной оценки качества модели проведена 5-Fold Cross-Validation. Результаты подтверждают, что модель не переобучена и хорошо обобщается на новые данные.

| Метрика | Среднее | Std |
|---------|---------|-----|
| ROC-AUC | 0.9587 | ±0.003 |
| Accuracy | 0.9235 | ±0.003 |
| Precision | 0.6887 | ±0.011 |
| Recall | 0.8443 | ±0.015 |
| F1-Score | 0.7585 | ±0.010 |

**Submission файлы:**

Submission файл — это CSV с предсказаниями модели на тестовых данных для отправки на Kaggle. Формат: id и предсказанная вероятность одобрения. Kaggle сравнивает предсказания с реальными ответами и возвращает итоговую метрику на лидерборде.

Pipeline обучен на всех тренировочных данных, сформированы submission файлы: `submission_proba.csv` с вероятностями и `submission_class.csv` с классами.

Файлы: `src/step7_final_pipeline/`  
Результаты: `data/submissions/`, `results/step7_final_pipeline/`

---

## Результаты

### Прогресс метрик по этапам

| Этап | Что сделали | ROC-AUC |
|------|-------------|---------|
| Step 1 | Logistic Regression baseline | ~0.87 |
| Step 3 | RF + One-Hot Encoding | ~0.92 |
| Step 3 | RF + Ordinal Encoding | ~0.93 |
| Step 4 | RF после очистки данных | ~0.935 |
| Step 5 | RF после Box-Cox | ~0.937 |
| Step 6 | LightGBM baseline | 0.9552 |
| Step 6 | LightGBM + Optuna | 0.9602 |
| Step 7 | LightGBM на train | 0.9756 |
| Step 7 | LightGBM 5-Fold CV | 0.9587 |

### Важность признаков

Box-Cox трансформация дохода `person_income_boxcox` стала самым важным признаком модели с долей 30.74%. Это подтверждает правильность решения о применении трансформации на этапе Feature Engineering.

| Признак | Importance | Доля (%) |
|---------|------------|----------|
| person_income_boxcox | 5654 | 30.74 |
| loan_int_rate | 3107 | 16.89 |
| loan_amnt | 2327 | 12.65 |
| loan_percent_income | 2162 | 11.76 |
| person_emp_length | 1745 | 9.49 |
| loan_intent | 1542 | 8.38 |
| person_home_ownership | 958 | 5.21 |
| loan_grade | 736 | 4.00 |
| cb_person_default_on_file | 161 | 0.88 |

---

## Как запустить

Клонирование репозитория:
```bash
git clone https://github.com/IvanMMMLich/loan-approval-prediction-v2.git
cd loan-approval-prediction-v2
```

Создание виртуального окружения:
```bash
python -m venv .venv
source .venv/bin/activate
```

Установка зависимостей:
```bash
pip install pandas numpy scikit-learn lightgbm xgboost catboost optuna matplotlib seaborn
```

Запуск Pipeline:
```bash
python src/step7_final_pipeline/pipeline_cv.py
python src/step7_final_pipeline/final_submission.py
```

---

## Выводы

### Понимание бинарной классификации

В ходе проекта получено глубокое понимание задачи бинарной классификации. Изучены метрики: Accuracy, Precision, Recall, F1-Score, ROC-AUC, Specificity. Стало понятно, почему для несбалансированных классов ROC-AUC лучше отражает качество модели, чем Accuracy. Освоена работа с матрицей ошибок и интерпретация TP, FP, TN, FN.

### Методы анализа данных

Изучено и применено большое количество методов анализа. Для числовых признаков: гистограммы, boxplot, skewness, kurtosis, IQR для выбросов. Для категориальных: bar chart, approval rate, Chi-square. Для анализа зависимостей использовано 19 различных методов: 9 для связи с таргетом, 3 для числовых корреляций, 2 для категориальных, 2 для смешанных и 3 model-based метода.

### Понимание предметной области

Открытие природы subprime кредитора показало важность понимания бизнес-логики данных. Без этого понимания корреляции интерпретировались бы неправильно, а Ordinal Encoding был бы настроен некорректно.

### Feature Engineering

Опробовано пять методов создания признаков: трансформации, комбинации, агрегации, бинарные флаги, доменные признаки. Строгий протокол проверки (корреляции, мультиколлинеарность, Permutation Importance) предотвратил добавление бесполезных признаков. Только Box-Cox трансформация дала реальное улучшение — и этот признак стал самым важным в финальной модели (30.74%).

### Выбор кодирования

Эксперимент с One-Hot vs Ordinal показал важность выбора метода кодирования. Для данных с естественным порядком категорий и древесных моделей Ordinal Encoding оказался лучшим выбором.

### Сравнение моделей

Изучены алгоритмы: логистическая регрессия, Random Forest, XGBoost, LightGBM, CatBoost. Проведено корректное сравнение в равных условиях.

### Оптимизация гиперпараметров

Освоена работа с Optuna для автоматического подбора гиперпараметров с использованием кросс-валидации. Понято назначение каждого параметра LightGBM и их влияние на качество модели.

### Pipeline и воспроизводимость

Создание sklearn Pipeline обеспечило отсутствие утечки данных и воспроизводимость результатов.

### Общие итоги

Проект потребовал значительных усилий. Проверено множество гипотез, большинство не подтвердились — это нормальная часть Data Science. Главный результат — модель с ROC-AUC 0.9756 на train и 0.9587 на кросс-валидации, а также полученный опыт системного подхода к машинному обучению.

---

## Автор

Сычёв Иван Александрович  
2025 год

GitHub: https://github.com/IvanMMMLich/loan-approval-prediction-v2